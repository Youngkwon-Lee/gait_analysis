"""
RESULTS_SUMMARY.md ê¸°ë°˜ ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”
(HPC ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì „ ì‚¬ì „ ì‹œê°í™”)
"""

import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import sys

# Windows ì½˜ì†” UTF-8 ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# ê²½ë¡œ ì„¤ì •
BASE_PATH = Path(__file__).parent.parent
VISUALIZATIONS_PATH = BASE_PATH / 'visualizations'
VISUALIZATIONS_PATH.mkdir(exist_ok=True)

# ìš°ë¦¬ ê²°ê³¼ (RESULTS_SUMMARY.md ê¸°ì¤€)
OUR_RESULTS = {
    'PD_Screening': {
        'auc': 0.963,
        'balanced_acc': 0.790,
        'sensitivity': 0.595,
        'specificity': 0.985
    },
    'OA_Screening': {
        'auc': 0.908,
        'balanced_acc': 0.786,
        'sensitivity': 0.668,
        'specificity': 0.904
    },
    'CVA_Detection': {
        'auc': 0.986,
        'balanced_acc': 0.936,
        'sensitivity': 0.958,
        'specificity': 0.914
    },
    'PD_vs_CVA': {
        'auc': 0.934,
        'balanced_acc': 0.880,
        'sensitivity': 0.942,
        'specificity': 0.819
    }
}

# ë² ì´ìŠ¤ë¼ì¸ ë…¼ë¬¸ ê²°ê³¼
BASELINE_RESULTS = {
    'PD_Screening': {'auc': 0.821, 'balanced_acc': 0.639},
    'OA_Screening': {'auc': 0.990, 'balanced_acc': 0.942},
    'CVA_Detection': {'auc': 0.950, 'balanced_acc': 0.747},
    'PD_vs_CVA': {'auc': 0.657, 'balanced_acc': 0.607}
}

# Task ì´ë¦„
TASK_NAMES = {
    'PD_Screening': 'PD Screening\n(HS vs PD)',
    'OA_Screening': 'OA Screening\n(HS vs HOA)',
    'CVA_Detection': 'CVA Detection\n(HS vs CVA)',
    'PD_vs_CVA': 'PD vs CVA'
}


def plot_auc_comparison():
    """ROC-AUC ë¹„êµ ë§‰ëŒ€ê·¸ë˜í”„"""

    tasks = list(TASK_NAMES.values())
    our_auc = [OUR_RESULTS[k]['auc'] for k in OUR_RESULTS.keys()]
    baseline_auc = [BASELINE_RESULTS[k]['auc'] for k in BASELINE_RESULTS.keys()]

    x = np.arange(len(tasks))
    width = 0.35

    fig, ax = plt.subplots(figsize=(12, 7))

    bars1 = ax.bar(x - width/2, our_auc, width, label='ìš°ë¦¬ ê²°ê³¼',
                   color='#FF6B6B', edgecolor='black', linewidth=1.2)
    bars2 = ax.bar(x + width/2, baseline_auc, width, label='ë…¼ë¬¸ (Baseline)',
                   color='#4ECDC4', edgecolor='black', linewidth=1.2)

    # ê°œì„ ë„ í‘œì‹œ (í™”ì‚´í‘œ)
    for i, (our, baseline) in enumerate(zip(our_auc, baseline_auc)):
        diff = our - baseline
        if diff > 0:
            # ìƒìŠ¹ í™”ì‚´í‘œ
            ax.annotate('', xy=(i, our), xytext=(i, baseline),
                       arrowprops=dict(arrowstyle='->', color='green', lw=2))
            ax.text(i, max(our, baseline) + 0.02, f'+{diff:.1%}',
                   ha='center', va='bottom', fontsize=10, fontweight='bold', color='green')
        else:
            # í•˜ë½ í™”ì‚´í‘œ
            ax.annotate('', xy=(i, our), xytext=(i, baseline),
                       arrowprops=dict(arrowstyle='->', color='red', lw=2))
            ax.text(i, min(our, baseline) - 0.02, f'{diff:.1%}',
                   ha='center', va='top', fontsize=10, fontweight='bold', color='red')

    # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{height:.3f}',
                   ha='center', va='bottom', fontsize=9, fontweight='bold')

    ax.set_xlabel('Task', fontsize=13, fontweight='bold')
    ax.set_ylabel('ROC-AUC', fontsize=13, fontweight='bold')
    ax.set_title('ROC-AUC ì„±ëŠ¥ ë¹„êµ (ìš°ë¦¬ vs ë² ì´ìŠ¤ë¼ì¸ ë…¼ë¬¸)',
                fontsize=15, fontweight='bold', pad=20)
    ax.set_xticks(x)
    ax.set_xticklabels(tasks, fontsize=10)
    ax.legend(fontsize=12, loc='lower right')
    ax.set_ylim([0.5, 1.05])
    ax.grid(True, alpha=0.3, axis='y', linestyle='--')
    ax.axhline(y=0.9, color='gray', linestyle=':', alpha=0.5, label='Excellent (0.9)')

    plt.tight_layout()

    save_path = VISUALIZATIONS_PATH / 'auc_comparison.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"[OK] AUC comparison saved: {save_path}")
    plt.close()


def plot_balanced_acc_comparison():
    """Balanced Accuracy ë¹„êµ ë§‰ëŒ€ê·¸ë˜í”„"""

    tasks = list(TASK_NAMES.values())
    our_acc = [OUR_RESULTS[k]['balanced_acc'] for k in OUR_RESULTS.keys()]
    baseline_acc = [BASELINE_RESULTS[k]['balanced_acc'] for k in BASELINE_RESULTS.keys()]

    x = np.arange(len(tasks))
    width = 0.35

    fig, ax = plt.subplots(figsize=(12, 7))

    bars1 = ax.bar(x - width/2, our_acc, width, label='ìš°ë¦¬ ê²°ê³¼',
                   color='#95E1D3', edgecolor='black', linewidth=1.2)
    bars2 = ax.bar(x + width/2, baseline_acc, width, label='ë…¼ë¬¸ (Baseline)',
                   color='#F38181', edgecolor='black', linewidth=1.2)

    # ê°œì„ ë„ í‘œì‹œ
    for i, (our, baseline) in enumerate(zip(our_acc, baseline_acc)):
        diff = our - baseline
        if diff > 0:
            ax.annotate('', xy=(i, our), xytext=(i, baseline),
                       arrowprops=dict(arrowstyle='->', color='green', lw=2))
            ax.text(i, max(our, baseline) + 0.02, f'+{diff:.1%}',
                   ha='center', va='bottom', fontsize=10, fontweight='bold', color='green')
        else:
            ax.annotate('', xy=(i, our), xytext=(i, baseline),
                       arrowprops=dict(arrowstyle='->', color='red', lw=2))
            ax.text(i, min(our, baseline) - 0.02, f'{diff:.1%}',
                   ha='center', va='top', fontsize=10, fontweight='bold', color='red')

    # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{height:.3f}',
                   ha='center', va='bottom', fontsize=9, fontweight='bold')

    ax.set_xlabel('Task', fontsize=13, fontweight='bold')
    ax.set_ylabel('Balanced Accuracy', fontsize=13, fontweight='bold')
    ax.set_title('Balanced Accuracy ì„±ëŠ¥ ë¹„êµ (ìš°ë¦¬ vs ë² ì´ìŠ¤ë¼ì¸ ë…¼ë¬¸)',
                fontsize=15, fontweight='bold', pad=20)
    ax.set_xticks(x)
    ax.set_xticklabels(tasks, fontsize=10)
    ax.legend(fontsize=12, loc='lower right')
    ax.set_ylim([0.5, 1.05])
    ax.grid(True, alpha=0.3, axis='y', linestyle='--')

    plt.tight_layout()

    save_path = VISUALIZATIONS_PATH / 'balanced_acc_comparison.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"[OK] Balanced Accuracy comparison saved: {save_path}")
    plt.close()


def plot_sensitivity_specificity():
    """Sensitivity & Specificity ë¹„êµ (ìš°ë¦¬ ê²°ê³¼ë§Œ)"""

    tasks = list(TASK_NAMES.values())
    sensitivity = [OUR_RESULTS[k]['sensitivity'] for k in OUR_RESULTS.keys()]
    specificity = [OUR_RESULTS[k]['specificity'] for k in OUR_RESULTS.keys()]

    x = np.arange(len(tasks))
    width = 0.35

    fig, ax = plt.subplots(figsize=(12, 7))

    bars1 = ax.bar(x - width/2, sensitivity, width, label='Sensitivity (ë¯¼ê°ë„)',
                   color='#FFD93D', edgecolor='black', linewidth=1.2)
    bars2 = ax.bar(x + width/2, specificity, width, label='Specificity (íŠ¹ì´ë„)',
                   color='#6BCB77', edgecolor='black', linewidth=1.2)

    # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{height:.3f}',
                   ha='center', va='bottom', fontsize=9, fontweight='bold')

    ax.set_xlabel('Task', fontsize=13, fontweight='bold')
    ax.set_ylabel('Score', fontsize=13, fontweight='bold')
    ax.set_title('Sensitivity & Specificity ë¶„ì„ (ìš°ë¦¬ ê²°ê³¼)',
                fontsize=15, fontweight='bold', pad=20)
    ax.set_xticks(x)
    ax.set_xticklabels(tasks, fontsize=10)
    ax.legend(fontsize=12)
    ax.set_ylim([0.5, 1.05])
    ax.grid(True, alpha=0.3, axis='y', linestyle='--')
    ax.axhline(y=0.9, color='gray', linestyle=':', alpha=0.5, label='Good (0.9)')

    plt.tight_layout()

    save_path = VISUALIZATIONS_PATH / 'sensitivity_specificity.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"[OK] Sensitivity/Specificity saved: {save_path}")
    plt.close()


def plot_improvement_heatmap():
    """ê°œì„ ë„ íˆíŠ¸ë§µ"""

    tasks = list(TASK_NAMES.values())

    # ê°œì„ ë„ ê³„ì‚°
    improvements = []
    for task_key in OUR_RESULTS.keys():
        auc_diff = OUR_RESULTS[task_key]['auc'] - BASELINE_RESULTS[task_key]['auc']
        acc_diff = OUR_RESULTS[task_key]['balanced_acc'] - BASELINE_RESULTS[task_key]['balanced_acc']
        improvements.append([auc_diff * 100, acc_diff * 100])

    improvements = np.array(improvements)

    fig, ax = plt.subplots(figsize=(10, 6))

    # ì»¬ëŸ¬ë§µ (ë¹¨ê°•=ë‚˜ì¨, ì´ˆë¡=ì¢‹ìŒ)
    im = ax.imshow(improvements.T, cmap='RdYlGn', aspect='auto', vmin=-20, vmax=50)

    # ì¶• ì„¤ì •
    ax.set_xticks(np.arange(len(tasks)))
    ax.set_yticks(np.arange(2))
    ax.set_xticklabels(tasks, fontsize=10)
    ax.set_yticklabels(['ROC-AUC', 'Balanced Accuracy'], fontsize=12, fontweight='bold')

    # ê°’ í‘œì‹œ
    for i in range(len(tasks)):
        for j in range(2):
            value = improvements[i, j]
            color = 'white' if abs(value) > 20 else 'black'
            text = ax.text(i, j, f'{value:+.1f}%',
                          ha="center", va="center", color=color,
                          fontsize=11, fontweight='bold')

    ax.set_title('ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ ê°œì„ ë„ (%)', fontsize=15, fontweight='bold', pad=20)

    # ì»¬ëŸ¬ë°”
    cbar = plt.colorbar(im, ax=ax)
    cbar.set_label('Improvement (%)', fontsize=11, fontweight='bold')

    plt.tight_layout()

    save_path = VISUALIZATIONS_PATH / 'improvement_heatmap.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"[OK] Improvement heatmap saved: {save_path}")
    plt.close()


def create_summary_table():
    """ì„±ëŠ¥ ìš”ì•½ í…Œì´ë¸” (ë§ˆí¬ë‹¤ìš´)"""

    lines = []
    lines.append("# ì„±ëŠ¥ ë¹„êµ ìš”ì•½í‘œ")
    lines.append("")
    lines.append("## ì „ì²´ ë¹„êµ")
    lines.append("")
    lines.append("| Task | ì§€í‘œ | ìš°ë¦¬ ê²°ê³¼ | ë…¼ë¬¸ | ê°œì„ ë„ | ë“±ê¸‰ |")
    lines.append("|------|------|-----------|------|--------|------|")

    for task_key, task_name in TASK_NAMES.items():
        our = OUR_RESULTS[task_key]
        baseline = BASELINE_RESULTS[task_key]

        # AUC
        auc_diff = our['auc'] - baseline['auc']
        auc_pct = (auc_diff / baseline['auc']) * 100
        auc_grade = "ğŸ”¥ğŸ”¥ğŸ”¥" if auc_pct > 20 else "ğŸ”¥ğŸ”¥" if auc_pct > 10 else "âœ…" if auc_pct > 0 else "âš ï¸"

        lines.append(f"| {task_name.replace(chr(10), ' ')} | **AUC** | **{our['auc']:.3f}** | {baseline['auc']:.3f} | **{auc_diff:+.3f}** ({auc_pct:+.1f}%) | {auc_grade} |")

        # Balanced Accuracy
        acc_diff = our['balanced_acc'] - baseline['balanced_acc']
        acc_pct = (acc_diff / baseline['balanced_acc']) * 100
        acc_grade = "ğŸ”¥ğŸ”¥ğŸ”¥" if acc_pct > 20 else "ğŸ”¥ğŸ”¥" if acc_pct > 10 else "âœ…" if acc_pct > 0 else "âš ï¸"

        lines.append(f"| {task_name.replace(chr(10), ' ')} | **Bal.Acc** | **{our['balanced_acc']:.3f}** | {baseline['balanced_acc']:.3f} | **{acc_diff:+.3f}** ({acc_pct:+.1f}%) | {acc_grade} |")

        # Sensitivity & Specificity (ìš°ë¦¬ë§Œ)
        lines.append(f"| {task_name.replace(chr(10), ' ')} | Sensitivity | {our['sensitivity']:.3f} | - | - | - |")
        lines.append(f"| {task_name.replace(chr(10), ' ')} | Specificity | {our['specificity']:.3f} | - | - | - |")

    lines.append("")
    lines.append("## ì£¼ìš” ì„±ê³¼")
    lines.append("")
    lines.append("### ğŸ† ìµœëŒ€ ê°œì„ ")
    lines.append("- **PD vs CVA**: AUC +0.277 (+42.2%) - ê°€ì¥ í° ê°œì„ ")
    lines.append("- **CVA Detection**: Bal.Acc +0.189 (+25.3%)")
    lines.append("- **PD Screening**: AUC +0.142 (+17.3%)")
    lines.append("")
    lines.append("### âš ï¸ ì„±ëŠ¥ ì €í•˜")
    lines.append("- **OA Screening**: AUC -0.082 (-8.3%)")
    lines.append("  - ì›ì¸: ìƒ˜í”Œ ë¶ˆê· í˜• (HOA 74ê°œ vs HS 360ê°œ)")
    lines.append("  - ê°œì„  ë°©í–¥: Data Augmentation, Class Weighting ì¡°ì •")
    lines.append("")
    lines.append("## ì„ìƒì  ì˜ì˜")
    lines.append("")
    lines.append("### CVA Detection (ë‡Œì¡¸ì¤‘ ê²€ì¶œ)")
    lines.append("- **Sensitivity 95.8%**: ë‡Œì¡¸ì¤‘ í™˜ì ëŒ€ë¶€ë¶„ ê²€ì¶œ")
    lines.append("- **Specificity 91.4%**: ê±´ê°•ì¸ ì˜¤ì§„ìœ¨ ë‚®ìŒ")
    lines.append("- **ì„ìƒ í™œìš©**: ì¡°ê¸° ìŠ¤í¬ë¦¬ë‹ ë„êµ¬ë¡œ í™œìš© ê°€ëŠ¥")
    lines.append("")
    lines.append("### PD Screening (íŒŒí‚¨ìŠ¨ë³‘ ìŠ¤í¬ë¦¬ë‹)")
    lines.append("- **Specificity 98.5%**: ê±´ê°•ì¸ì„ PDë¡œ ì˜¤ì§„í•˜ëŠ” ê²½ìš° ê·¹íˆ ë“œë¬¾")
    lines.append("- **Sensitivity 59.5%**: ì¼ë¶€ PD í™˜ì ë¯¸ê²€ì¶œ - ê°œì„  í•„ìš”")
    lines.append("- **ì„ìƒ í™œìš©**: False Positive ìµœì†Œí™”, 2ì°¨ ê²€ì‚¬ ì˜ë¢° ê¸°ì¤€")
    lines.append("")
    lines.append("### PD vs CVA (ê°ë³„ ì§„ë‹¨)")
    lines.append("- **íšê¸°ì  ê°œì„ **: ë…¼ë¬¸ 0.657 â†’ ìš°ë¦¬ 0.934")
    lines.append("- **Sensitivity 94.2%**: PD í™˜ì ì •í™• ë¶„ë¥˜")
    lines.append("- **Specificity 81.9%**: CVA í™˜ì ì •í™• ë¶„ë¥˜")
    lines.append("- **ì„ìƒ í™œìš©**: ì›¨ì–´ëŸ¬ë¸” ì„¼ì„œ ê¸°ë°˜ ì‹ ê²½ì§ˆí™˜ ê°ë³„ ê°€ëŠ¥ì„± ì…ì¦")

    save_path = VISUALIZATIONS_PATH / 'PERFORMANCE_SUMMARY.md'
    save_path.write_text('\n'.join(lines), encoding='utf-8')
    print(f"[OK] Performance summary table saved: {save_path}")


def main():
    print("=" * 60)
    print("Performance Comparison Visualization")
    print("=" * 60)
    print("")

    print("1. ROC-AUC comparison...")
    plot_auc_comparison()

    print("2. Balanced Accuracy comparison...")
    plot_balanced_acc_comparison()

    print("3. Sensitivity/Specificity...")
    plot_sensitivity_specificity()

    print("4. Improvement heatmap...")
    plot_improvement_heatmap()

    print("5. Performance summary table...")
    create_summary_table()

    print("")
    print("=" * 60)
    print(f"All visualizations completed!")
    print(f"Saved to: {VISUALIZATIONS_PATH}")
    print("=" * 60)
    print("")
    print("Generated files:")
    print("  - auc_comparison.png")
    print("  - balanced_acc_comparison.png")
    print("  - sensitivity_specificity.png")
    print("  - improvement_heatmap.png")
    print("  - PERFORMANCE_SUMMARY.md")


if __name__ == '__main__':
    main()
